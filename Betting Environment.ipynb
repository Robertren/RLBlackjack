{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Betting Environment\n",
    "Some basic parameters\n",
    "- Observation Space (State Space): $\\mathbb{R}^2$, one dimension is **Current total money**, the other dimension is **Last reward**. Or we can start with only the first dimension only?\n",
    "- Action Space: 10 dimension, each dimension correspond to 1 unit bet to 10 times unit bets.\n",
    "- Step function:\n",
    "\n",
    "    1. Take bet\n",
    "    2. Let BlackJack Agent run until done, get either win or lose.\n",
    "    3. Calculate Reward based on win/lose and betting amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch.optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from tqdm import tqdm\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "# Betting Environment\n",
    "class BlackjackBetEnv(object):\n",
    "    def __init__(\n",
    "        self , \n",
    "        blackjack_agent_class, \n",
    "        pretrained_agent_path=None,\n",
    "        cotrain_blackjack_agent=True,\n",
    "        obs_limit=128, \n",
    "        init_money=0,\n",
    "        n_actions=10\n",
    "                ):\n",
    "        self.blackjack_agent_class = blackjack_agent_class\n",
    "        self.init_money = init_money\n",
    "        # Setup environment for playing each round of blackjack\n",
    "        self.env_blackjack = gym.make('Blackjack-v0')\n",
    "        self.env_blackjack.reset()\n",
    "        self.agent_blackjack = blackjack_agent_class(n_inputs=16, n_outputs=2, gamma=0.75)\n",
    "        self.cotrain_blackjack_agent=cotrain_blackjack_agent\n",
    "        if pretrained_agent_path is not None:\n",
    "            self.agent_blackjack.load_state_dict(torch.load(pretrained_agent_path))\n",
    "        # Observation and State spaces\n",
    "        high = np.array([obs_limit])\n",
    "        self.observation_space = spaces.Box(-high, high)\n",
    "        self.action_space = spaces.Discrete(n_actions)\n",
    "        self.money_remain = init_money\n",
    "        # Reset random seed\n",
    "        self.seed()\n",
    "        self.reset()\n",
    "\n",
    "    def _transfer_card_input(self, player, dealer):\n",
    "        # transfer the dealer and player card into a fixed dimension list\n",
    "        deal_card = [dealer[0]]\n",
    "        player_card = player + [0] * (15 - len(player))\n",
    "        return player_card + deal_card\n",
    "\n",
    "    def step(self, action):\n",
    "        round_finished = False\n",
    "        while not round_finished:\n",
    "            blackjack_state = self._transfer_card_input(self.env_blackjack.player, self.env_blackjack.dealer)\n",
    "            # Agent choose\n",
    "            blackjack_agent_action = self.agent_blackjack.choose(blackjack_state)\n",
    "            # Update observation\n",
    "            blackjack_obs, blackjack_reward, round_finished, _ = self.env_blackjack.step(blackjack_agent_action)\n",
    "            # Agent Remember and Learn\n",
    "            if self.cotrain_blackjack_agent:\n",
    "                blackjack_next_state = self._transfer_card_input(self.env_blackjack.player, self.env_blackjack.dealer)\n",
    "                self.agent_blackjack.remember(\n",
    "                    blackjack_state, \n",
    "                    blackjack_agent_action, \n",
    "                    blackjack_next_state,\n",
    "                    blackjack_reward\n",
    "                )\n",
    "                self.agent_blackjack.learn()\n",
    "            # Optional print statement for examination\n",
    "#             print('Player card:',self.env_blackjack.player)\n",
    "#             print('Dealer card:',self.env_blackjack.dealer)\n",
    "#             print('Agent Action:', blackjack_agent_action)\n",
    "#             print('round_finished:', round_finished)\n",
    "#             print('Blackjack_reward:', blackjack_reward)\n",
    "#             print()\n",
    "        bet_reward = blackjack_reward*(action+1)\n",
    "        self.env_blackjack.reset()\n",
    "        self.money_remain += bet_reward\n",
    "        done = self.observation_space.contains(np.array([self.money_remain])) == False\n",
    "        return [self.money_remain], bet_reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.money_remain = self.init_money\n",
    "        self.env_blackjack.reset()\n",
    "        # return initial state\n",
    "        return [0.]\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "# Blackjack Playing Agent \n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None) # grow the memory\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position+1)%self.capacity # loop around\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "BATCH_SIZE = 128\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "steps_done = 0\n",
    "\n",
    "class NetworkAgent(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_outputs, gamma, lr=0.00015):\n",
    "        self.H = 128 # the number of hidden units (you can change this or make it a parameter)\n",
    "        self.MEM_SIZE = 100 # could be made a parmaeter\n",
    "        self.BATCH_SIZE = 64\n",
    "        nn.Module.__init__(self)\n",
    "        self.num_inputs = n_inputs\n",
    "        self.num_actions = n_outputs\n",
    "        self.l1 = nn.Linear(self.num_inputs, self.H) # defines the input units and layer 1 weights\n",
    "        self.l2 = nn.Linear(self.H, 10) # defines the output units (actions) and layer 2 weights\n",
    "        self.l3 = nn.Linear(10, self.num_actions)\n",
    "        self.memory = ReplayMemory(self.MEM_SIZE) # create a replay memory \n",
    "        self.gamma = gamma\n",
    "        self.optimizer = torch.optim.RMSprop(self.parameters(), lr = lr)\n",
    "    \n",
    "    # makes forward predictions from the current state, x, to the actions\n",
    "    def forward(self, x):\n",
    "        # the forward function is required by the neural network and takes an input\n",
    "        # vector (x) representing in this case the current state and makes a prediction\n",
    "        # about the activation of the output units in the network.\n",
    "        x = F.relu(self.l1(x)) # state -> hidden -> relu()\n",
    "        x = F.relu(self.l2(x)) # hidden -> hidden\n",
    "        x = F.softmax(self.l3(x))\n",
    "        return x \n",
    "    \n",
    "    # makes a choice about which action to perform (left=0, right=1)\n",
    "    def choose(self, state):\n",
    "        #### YOUR CODE HERE\n",
    "        \n",
    "        # you should implement a rule for making choices.\n",
    "        # you can use any of the algorithms discussed in class or that you used in the \n",
    "        # earlier part of the homework (softmax, ucb)\n",
    "        # however, you will want to based your actions somewhat on the network's\n",
    "        # predictions about what to do:\n",
    "        # \n",
    "        # to give you a hint the following set of lines\n",
    "        # show how to use the network to make a forward prediction:\n",
    "        #        state_vec = Variable(FloatTensor([state]), volatile=True).type(FloatTensor)\n",
    "        #        self(state_vec)\n",
    "        # specifcally, calling self(state_vec) run the self.forward() function defined above\n",
    "        \n",
    "        # right now the algorithm ignores the current state and network\n",
    "        # but will need to decide based on this later.\n",
    "        global steps_done\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "        steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            state_vec = Variable(FloatTensor([state]), volatile=True).type(FloatTensor)\n",
    "            action = self(state_vec).max(1)[1].data.numpy()[0]\n",
    "            return action\n",
    "        else:\n",
    "            return random.randrange(2)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # stores the last state, action pair in a format that is useful to the network\n",
    "    def remember(self, *args):\n",
    "        args = (FloatTensor([args[0]]),\n",
    "               args[1],\n",
    "               FloatTensor([args[2]]),\n",
    "               FloatTensor([args[3]]))\n",
    "        self.memory.push(*args)\n",
    "    \n",
    "    def learn(self):\n",
    "        if len(self.memory) < self.BATCH_SIZE:\n",
    "            return # don't do learning if you haven't accumulated enough experience yet (this could be improved)\n",
    "        # get a bunch of training data\n",
    "        transitions = self.memory.sample(self.BATCH_SIZE)\n",
    "        batch_state, batch_action, batch_next_state, batch_reward = zip(*transitions)\n",
    "    \n",
    "        # convert to variables (necessary for batch training)\n",
    "        batch_state = Variable(torch.cat(batch_state))\n",
    "        batch_action = Variable(torch.from_numpy(np.array(batch_action)).view(self.BATCH_SIZE, -1))\n",
    "        batch_next_state = Variable(torch.cat(batch_next_state), requires_grad=False)\n",
    "        batch_reward = Variable(torch.cat(batch_reward), requires_grad=False)\n",
    "        # steps to be implemented:\n",
    "        # 1. compute current Q values for all actions\n",
    "        state_action_values = self(batch_state).gather(1, batch_action)\n",
    "        \n",
    "        # 2. compute exected Q values estimated from action which given max Q values (on-policy)\n",
    "        next_state_values = self(batch_next_state).max(1)[0]\n",
    "        expected_state_action_values = (next_state_values * self.gamma) + batch_reward\n",
    "        # Rebuild Variable \n",
    "        expected_state_action_values = Variable(expected_state_action_values.data, requires_grad=False)\n",
    "\n",
    "        # 3. compute the loss/error function (one suggestion is F.smooth_l1_loss())\n",
    "#         print('state:')\n",
    "#         print(state_action_values.view(-1))\n",
    "#         print('expected:')\n",
    "#         print(expected_state_action_values)\n",
    "#         print(expected_state_action_values.requires_grad)\n",
    "#         expected_state_action_values.detach()\n",
    "#         print(expected_state_action_values.requires_grad)\n",
    "        loss = F.smooth_l1_loss(state_action_values.view(-1), expected_state_action_values)\n",
    "        \n",
    "        # 4. apply the error and backprop the gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        \n",
    "        #### YOUR CODE HERE\n",
    "        # this is where you will implement the Q-learning update rules on the a batch of\n",
    "        # sampled examples from the replay memory\n",
    "        # a couple of resources:\n",
    "        #  - check out Homework 2, particularly the RNN code for how to train a network using pytorch\n",
    "        #  - check out the nn.Module docs on the pytorch website: http://pytorch.org/docs/master/nn.html\n",
    "        #  - check out this pytorch doc on implementing a DQN: http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "        # it is ok if you want to modify any of the starter code to use a different\n",
    "        # format.  However your solution MUST involve a multi-layer neural network as\n",
    "        # the function approximation representation for the DQN.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "bet_env = BlackjackBetEnv(\n",
    "    blackjack_agent_class=NetworkAgent,\n",
    "    cotrain_blackjack_agent=False,\n",
    "    pretrained_agent_path='./model.p'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bet Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conservative Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConservativeBetAgent(NetworkAgent):\n",
    "    def __init__(self, n_inputs, n_outputs, gamma=0.75):\n",
    "        super(ConservativeBetAgent, self).__init__(n_inputs=n_inputs, n_outputs=n_outputs, gamma=0.75)\n",
    "\n",
    "    def learn(self):\n",
    "        pass\n",
    "    \n",
    "    def choose(self, state):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_bet_agent = ConservativeBetAgent(n_inputs=1, n_outputs=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_bet_agent = NetworkAgent(n_inputs=1, n_outputs=10, gamma=0.75, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, agent):\n",
    "    \n",
    "    # Run the environment\n",
    "    state = env.reset()  \n",
    "    duration = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        duration += 1\n",
    "        # use network to choose action here\n",
    "        action = agent.choose(state) # choose action based on current state\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        # the even returns done=True when the take stops\n",
    "        \n",
    "        # see below but the agent includes a memory of the state, action, next_state, and reward\n",
    "        # which can be helpful for training (replay)\n",
    "        agent.remember(state, action, next_state, reward) # record what happened in memory\n",
    "    \n",
    "        # optimize the neural network model here (i.e., adjust learning weight)\n",
    "        # you will implement this function\n",
    "        agent.learn()\n",
    "        \n",
    "        # update the state\n",
    "        state = next_state\n",
    "        \n",
    "    \n",
    "    # return duration\n",
    "    return duration\n",
    "\n",
    "def train(env, agent, n_episodes = 1000):\n",
    "    duration_hist = []\n",
    "    pbar = ProgressBar()\n",
    "    for i in pbar(range(n_episodes)):\n",
    "        duration = run_episode(env, agent)\n",
    "        duration_hist.append(duration)\n",
    "    return duration_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of Deep Q Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 1000) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:170: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:144: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100% (1000 of 1000) |#####################| Elapsed Time: 0:05:03 Time: 0:05:03\n"
     ]
    }
   ],
   "source": [
    "duration_hist_deepbet = train(env=bet_env, agent=deep_bet_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_history(history_list, rolling_window=30, ylabel='Remain Money', ax=None, label=None):\n",
    "    history_df = pd.Series(history_list)\n",
    "    rolling_mean = history_df.rolling(window=rolling_window, center=False).mean()\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "    ax.plot(\n",
    "        rolling_mean,\n",
    "        label=label\n",
    "    )\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel('n_rounds')\n",
    "    return ax\n",
    "\n",
    "def evaluate(env, agent, n_rounds=1000, n_trial=1000):\n",
    "    remain_money_hist = np.zeros(n_rounds)\n",
    "    pbar = ProgressBar()\n",
    "    for i in pbar(range(n_trial)):\n",
    "        state = env.reset()\n",
    "        for i in range(n_rounds):\n",
    "            remain_money_hist[i] += state[0]\n",
    "            action = agent.choose(state)\n",
    "            state, _, _, _ = env.step(action)\n",
    "    remain_money_hist /= n_trial\n",
    "    return remain_money_hist\n",
    "\n",
    "# We need basically same agent for playing black jack. \n",
    "# Except a different learning and remenber method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:170: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:144: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100% (100 of 100) |#######################| Elapsed Time: 0:00:25 Time: 0:00:25\n"
     ]
    }
   ],
   "source": [
    "history_conservative = evaluate(bet_env, conservative_bet_agent, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:170: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:144: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100% (100 of 100) |#######################| Elapsed Time: 0:00:35 Time: 0:00:35\n"
     ]
    }
   ],
   "source": [
    "history_deepbet = evaluate(bet_env, deep_bet_agent, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a1edc90f0>"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAELCAYAAAAY3LtyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a200c3f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plot_history(history_conservative, ax=ax, label='conservative')\n",
    "plot_history(history_deepbet, ax = ax, label='deepbet')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:170: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/Users/zhuorulin/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:144: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_bet_agent.choose([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
